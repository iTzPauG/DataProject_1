# üíª DATA PROJECT: MONITORIZACI√ìN DE LA CALIDAD DEL AIRE

****

Este proyecto se basa en el dise√±o e implementaci√≥n de una **arquitectura moderna de Ingenier√≠a de Datos (Data Engineering)** para la ingesta, almacenamiento, transformaci√≥n y explotaci√≥n de datos de la calidad del aire procedentes de los portales de Datos Abiertos de Madrid y Valencia.

## 0. EQUIPO:
1. PAU GARCIA

2. DANIEL ADAM

3. GEMMA BALAGUER

## 1. üéØ Presentaci√≥n y Objetivos del Proyecto

El Data Project simula un entorno de trabajo real, requiriendo la integraci√≥n de datos p√∫blicos, dise√±o arquitect√≥nico y toma de decisiones t√©cnicas para abordar la monitorizaci√≥n de la calidad del aire.

### Objetivos Clave

* **Integraci√≥n de Fuentes:** Integrar m√∫ltiples fuentes de datos heterog√©neas (APIs de Madrid y Valencia).
* **Transformaci√≥n y Calidad:** Homogeneizar, limpiar y transformar datos a trav√©s de procesos automatizados (dbt).
* **Arquitectura H√≠brida:** Garantizar una arquitectura escalable, modular y desacoplada (Kafka) para manejar **Streaming** y **Batch**.
* **Entrega BI:** Publicar los datos procesados para el an√°lisis a trav√©s de Tableau BI.
* **Mantenibilidad:** Dise√±ar un *pipeline* reproducible, mantenible y **versionado** con Git.

***

## 2. ‚öôÔ∏è Dise√±o de Arquitectura y Justificaci√≥n de Piezas

La arquitectura implementa un **sistema h√≠brido** que maneja el **an√°lisis hist√≥rico (Batch BI)** y el **monitoreo de baja latencia (Streaming)**, siguiendo el paradigma **ELT (Extract, Load, Transform)**.

### A. Capa de Ingesta y Fuente de Verdad

| Componente | Justificaci√≥n Estrat√©gica | Archivos de Evidencia |
| :--- | :--- | :--- |
| **APIs y API Gateway** | **Centraliza la seguridad y gesti√≥n de tr√°fico** (*rate limiting*). Se requieren *scripts* individualizados para fuentes heterog√©neas. | `ingestas/ingesta_madrid.py`, `ingestas/ingesta_valencia.py`, `api.py`. |
| **DB PROD (DuckDB)** | Act√∫a como destino inicial de la carga (la 'L' en ELT) y **Fuente de Verdad Operacional**. **DuckDB** se elige por su **excelente rendimiento en consultas anal√≠ticas** y f√°cil integraci√≥n con Docker, optimizando el costo. | `dev.duckdb`, `ingesta.py`. |

### B. Flujo de Eventos y Streaming (Tiempo Real) ‚ö°

| Componente | Justificaci√≥n Estrat√©gica Extendida | Archivos de Evidencia |
| :--- | :--- | :--- |
| **Bus de Eventos Kafka** | Es la **espina dorsal del *streaming***. Ofrece **desacoplamiento total**, **tolerancia a fallos** y capacidad para manejar **picos de alta concurrencia** (recibe "Nuevos Datos" v√≠a CDC). | `/kafka/docker-compose.yml`, `producer.py`, `kafka_consumer.py`. |
| **Dashboard de Alertas (Plotly)** | Componente dedicado a la **baja latencia**. Muestra **alertas casi instant√°neamente**, crucial para el monitoreo operacional. | `dashboard_alertas.py`. |

### C. Transformaci√≥n Anal√≠tica y Modelado (dbt) üõ†Ô∏è

| Componente | Justificaci√≥n Estrat√©gica Extendida | Archivos de Evidencia |
| :--- | :--- | :--- |
| **dbt (Data Build Tool)** | Implementa el paradigma **ELT**. Permite **versionar** el c√≥digo SQL en Git y realizar **pruebas automatizadas** de calidad de datos, garantizando la **confiabilidad** y **auditor√≠a** del dato. | Estructura `/dbt`, pruebas `unique_...sql`. |
| **Estructura en Capas** | Adopci√≥n del est√°ndar **Staging ‚Üí Intermediate ‚Üí Marts** para crear un **linaje de datos claro** y modular, optimizando la mantenibilidad. | Directorios `/staging`, `/intermediate`, `/marts`. |

## 3. üíæ VISUALIZACI√ìN DE LOS DATOS.

### A. DASHBOARD DE LA CALIDAD DEL AIRE

Los datos de este archivo provienen de la tabla mediciones que se encuentra en la base de datos Data_Project_1. 

**Variables empleadas**:

| Columna | Descripci√≥n | Ejemplo de Dato |
| :--- | :--- | :--- |
| **Lat, Lon** | Coordenadas geogr√°ficas de la estaci√≥n (latitud y longitud). | 40.4514734, -3.6773491 |
| **Id** | Identificador √∫nico de la estaci√≥n. | 1813 |
| **Nombre estaci√≥n** | Nombre descriptivo de la estaci√≥n de monitoreo. | Avda. Ram√≥n y Cajal |
| **Ciudad** | Ciudad donde se encuentra la estaci√≥n. | Madrid |
| **is_latest** | Indica si es el dato m√°s reciente (`True` o `False`). | True |
| **No2** | Concentraci√≥n de **Di√≥xido de Nitr√≥geno** $(\text{NO}_2)$ en $\mu g/m^3$. | 9 |
| **O3** | Concentraci√≥n de **Ozono** $(\text{O}_3)$ en $\mu g/m^3$. | 49 |
| **Pm10, Pm25** | Concentraci√≥n de **Part√≠culas en Suspensi√≥n** (di√°metros $\le 10\mu m$ y $\le 2.5\mu m$). | 6, 4 |

**Objetivo de la visualizaci√≥n**

El objetivo principal es conseguir un mapa interactivo que permita a los usuarios: 
1. Identificar geogr√°ficamente todas las estaciones de monitoreo. 
2. Evaluar r√°pidamente el nivel de un contaminante clave mediante la codifcaci√≥n por color con marcadores. 
3. Consultar los calores exactos de todos los contaminantes y los detalles de la estaci√≥n al hacer clic sobre el marcador. 

**Mapeo de colores**:

| Rango de contaminante | Color | Significado |
| :--- | :--- | :--- |
| Bajo | Verde | Buena Calidad |
| Medio | Amarillo | Calidad Aceptable | 
| Alto | Rojo | Mala Calidad |



## 4. üîé Origen de Datos y Flujo de Entrega (BI)

### A. Datasets Explorados y Justificaci√≥n

| Dataset | Origen | Decisi√≥n | Justificaci√≥n | URL |
| :--- | :--- | :--- | :--- | :--- |
| **Calidad del Aire - Tiempo Real** | API Madrid | **INCLUIDO** | Proporciona los datos horarios necesarios para el **monitoreo en tiempo real**. | `https://ciudadesabiertas.madrid.es/dynamicAPI/API/query/calair_tiemporeal.json?pageSize=5000` |
| **Estaciones Contaminaci√≥n Atmosf√©rica** | API Valencia | **INCLUIDO** | Fuente de datos cr√≠tica para el an√°lisis geogr√°fico y la construcci√≥n de la **dimensi√≥n de la estaci√≥n**. | `https://valencia.opendatasoft.com/api/records/1.0/search/?dataset=estacions-contaminacio-atmosferiques-estaciones-contaminacion-atmosfericas&rows=1000` |


### B. Estructura del Repositorio Git y Entrega de BI üìä

| Carpeta / Archivo | Rol en la Arquitectura | Descripci√≥n / Instrucciones |
| :--- | :--- | :--- |
| **`README.md`** | **Instrucciones Principales** | Contiene el dise√±o de la arquitectura, la justificaci√≥n y los pasos de ejecuci√≥n. |
| **`requirements.txt`** | **Entorno Python** | Lista las librer√≠as necesarias para la reproducibilidad del entorno. |
| **`docker-compose.yml`** | **Infraestructura** | Define y orquesta los contenedores (Kafka, DB, Python/dbt). |
| **`/ingestas`** | Ingesta | Scripts de extracci√≥n de las APIs. |
| **`/kafka`** | Infraestructura Streaming | Configuraci√≥n de los servicios de Kafka y Zookeeper. |
| **`producer.py` / `kafka_consumer.py`** | Streaming | Scripts de env√≠o y recepci√≥n de datos por Kafka. |
| **`/dbt/models`** | Transformaci√≥n (ELT) | Contiene la l√≥gica SQL de modelado (`staging`, `intermediate`, `marts`). |
| **`pull_db_gsheets.py`** | Entrega BI | Script de *Reverse ETL* que extrae los *marts* para Tableau. |

## 5. ‚öôÔ∏è Ejecuci√≥n del Proyecto

El proyecto est√° dise√±ado para una ejecuci√≥n automatizada de principio a fin usando Docker Compose.

### A. Requisitos
* Docker Desktop (o Docker Engine y Docker Compose).
* Acceso a las APIs de datos abiertos (se requiere la configuraci√≥n de credenciales si aplica, en el archivo `.env`).

### B. Pasos de Ejecuci√≥n (Comando √önico)

Desde el directorio ra√≠z del proyecto:

1.  **Arranque Completo del Pipeline (Batch y Streaming):**
    Este comando construye las im√°genes, lanza la infraestructura (DB, Kafka) y ejecuta autom√°ticamente las ingestas iniciales, la transformaci√≥n con dbt, y el flujo de streaming (producer, consumer, dashboard).

    ```bash
    docker-compose up -d --build
    ```

2.  **Verificaci√≥n de Servicios:**
    Aseg√∫rate de que todos los contenedores est√©n levantados y sanos.

    ```bash
    docker-compose ps
    ```

3.  **Monitoreo del Dashboard:**
    Accede al dashboard de alertas en tiempo real:

    ```
    Abrir navegador: http://localhost:8050
    ```

### C. Consulta y Administraci√≥n
| Servicio | URL Local | Descripci√≥n |
| :--- | :--- | :--- |
| **Dashboard** | `http://localhost:8050` | Visualizaci√≥n de alertas de baja latencia. |
| **Kafka UI (Kafbat)** | `http://localhost:8080` | Monitoreo del flujo de mensajes. |
| **pgAdmin** | `http://localhost:5050` | Acceso a PostgreSQL (servidor: `db`, puerto: 5432). |

### D. Limpieza
Para detener todos los servicios y eliminar los contenedores (usar `-v` para borrar tambi√©n los datos persistentes de la base de datos):

```bash
docker-compose down
```
# docker-compose down -v  (Si quieres borrar los datos de Postgres)

