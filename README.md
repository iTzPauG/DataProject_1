# **üí® DATA PROJECT I: Sistema de Monitorizaci√≥n de la Calidad del Aire**

**M√°ster en Big Data & Cloud 2025-2026**
**Tutor**: Pedro Nieto. 
**Participantes**: Daniel Adam, Gemma Balaguer, Pau Garcia. 

## **1. INTORDUCCI√ìN**
El presente proyecto desarrolla un pipeline de datos integral orientado a la monitorizaci√≥n en tiempo real de la calidad del aire en las ciudades de Madrid y Valencia. La soluci√≥n implementada aborda todas las fases del ciclo de vida del dato: ingesta, estandarizaci√≥n, almacenamiento, transformaci√≥n, streaming, visualizaci√≥n y distribuci√≥n hacia herramientas de an√°lisis avanzado.

El dise√±o propuesto responde a la necesidad de disponer de sistemas automatizados, fiables y escalables que permitan emitir alertas inmediatas a la poblaci√≥n y proporcionar informaci√≥n detallada a organismos de gesti√≥n y toma de decisiones. Para ello, se ha construido una arquitectura modular apoyada en tecnolog√≠as ampliamente adoptadas en entornos de datos modernos.

## **2. Stack Tecnol√≥gico.**

**Ingesta** -> Python -> Obtenci√≥n de datos desde APIs oficiales y procesamiento. 

**Almacenamiento** -> PostgreSQL -> Base de datos relacional para datos brutos y modelos anal√≠ticos. 

**Transformaci√≥n** -> dbt -> Construcci√≥n de modelos, liempieza y generaci√≥n de data marts. 

**Procesamiento en Tiempo real** -> Kafka -> publicaci√≥n y consumo de eventos para alertas instant√°neas.

**Visualizaci√≥n** -> Plotly/Tableau ->  Dashboards operativos y anal√≠ticos para distintos perfiles de usuario.

**Orquestaci√≥n** - > Docker Compose -> Gesti√≥n y despliegue reproducible de todos los servicios.

## **3.ARQUITECTURA DEL PROYECTO**
![arquitectura](image-1.png)

La arquitectura integra m√∫ltiples componentes coordinados para garantizar un flujo de datos robusto y automatizado. Se detallan a continuaci√≥n sus principales etapas.

#### **3.1. Ingesta de Datos**

La carpeta /ingestas contiene los scripts ingesta_madrid.py e ingesta_valencia.py, responsables de:

- Conectarse a las APIs oficiales de ambos ayuntamientos.

- Descargar los datos de calidad del aire en formato JSON.

- Realizar las transformaciones necesarias para estandarizar las estructuras.

- Enviar los datos procesados a una API interna mediante solicitudes HTTP POST.

Esta capa permite aislar la l√≥gica espec√≠fica de cada proveedor de datos, manteniendo un dise√±o modular y extensible.

#### **3.2. API Gateway**

El archivo api.py act√∫a como punto de entrada √∫nico al sistema. Su funci√≥n es:

- Validar el contenido recibido desde los scripts de ingesta.

- Homogeneizar la informaci√≥n independientemente del origen.

- Insertar los datos en la base de datos relacional.

Esta estrategia evita la conexi√≥n directa de m√∫ltiples componentes a la base de datos y facilita la gobernanza del sistema.

#### **3.3. Almacenamiento en PostgeSQL**

La base de datos data_project_1 constituye el repositorio central del pipeline.
Almacena:

- Datos crudos (raw layer) procedentes de la API.

- Modelos transformados y tablas anal√≠ticas creadas mediante dbt.

Su naturaleza relacional permite un control estructurado y un acceso eficiente para las capas posteriores.

#### **3.4. Transformaci√≥n con dbt**

El proyecto dbt ejecuta las transformaciones necesarias para:

- Limpiar y normalizar las mediciones.

- Generar m√©tricas y agregaciones relevantes.

- Construir la capa final de data marts destinada a herramientas de an√°lisis.

dbt garantiza reproducibilidad, control de versiones e integraci√≥n directa con PostgreSQL.

#### **3.5. Procesamiento en Tiempo Real con KAFKA**

El ecosistema Kafka se compone de:

Producer (producer.py): consulta peri√≥dicamente la base de datos y publica nuevos registros en un topic dedicado.

- Consumer (dashboard_consumer.py): consume los mensajes recibidos y actualiza un dashboard operativo en Plotly, permitiendo visualizar alertas pr√°cticamente en tiempo real.

- Este componente habilita la comunicaci√≥n as√≠ncrona entre sistemas y permite escalar la arquitectura con m√∫ltiples consumidores especializados.

#### **3.6. Entrega Herramientas de BI**

Dado que Tableau no accede directamente a PostgreSQL en este entorno, el script pull_db_gsheets.py exporta los modelos finales a Google Sheets. Tableau consume estas hojas para generar dashboards de an√°lisis avanzado dirigidos a perfiles expertos.

## **4. Ejecuci√≥n del Proyecto**

El despliegue completo se realiza mediante Docker, lo que garantiza reproducibilidad y facilita la puesta en marcha del ecosistema.

#### **4.1. Requisitos previos**

1. Docker Engine o Docker Desktop instalado.

2. Docker Compose operativo.

3. Archivo .env configurado (si corresponde).

#### **4.2. Inicio del sistema**

Para desplegar todos los servicios (PostgreSQL, Kafka, API, dbt, dashboards, etc.) se utiliza el siguiente comando:

``` sh
docker compose up -d

```
Este proceso construye las im√°genes necesarias, levanta los contenedores y activa los flujos de ingesta, transformaci√≥n y procesamiento en tiempo real.

#### **4.2. Verificaci√≥n del estado de los servicios**
Permite comprobar que todos los contenedores se encuentran en ejecuci√≥n y en estado saludable.

```sh
docker compose ps
```
#### **4.3. Monitorizaci√≥n de los dashboards.**

- Alertas en tiempo real (Plotly)

Interfaz destinada a simular la visualizaci√≥n que tendr√≠a un usuario final (ciudadan√≠a).
Acceso desde el navegador:

üëâ http://localhost:8050

- Dashboards en tableau.
Acceso del usuario: 

üëâ  https://public.tableau.com/app/profile/daniel.adam5716/viz/CalidadAireDP_varias/Alertas

## **4. Origen de Datos y Flujo de Entrega**

#### **4.1. Origen de Datos**

**Calidad del Aire-Tiempo real** - > API Ayuntamiento de Madrid -> https://ciudadesabiertas.madrid.es/dynamicAPI/API/query/calair_tiemporeal.json?pageSize=5000

**Estaciones de Contaminaci√≥n Atmosf√©rica** ->API Ayuntamiento de Valencia ->https://valencia.opendatasoft.com/api/records/1.0/search/?dataset=estacions-contaminacio-atmosferiques-estaciones-contaminacion-atmosfericas&rows=1000


Ambas fuentes proporcionan datos fiables, auditables y con garant√≠as institucionales, requisito esencial para un sistema que puede ser utilizado en un contexto de salud p√∫blica.

#### 4.2. Estructura del Repositorio y Rol de Cada Componente

Este documento describe la organizaci√≥n del repositorio y la funci√≥n espec√≠fica de cada carpeta y archivo dentro de la arquitectura general del proyecto.

---

## üèóÔ∏è Componentes de la Arquitectura

| Carpeta / Archivo | Rol en la Arquitectura | Descripci√≥n |
| :--- | :--- | :--- |
| **README.md** | **Documentaci√≥n General** | Proporciona una visi√≥n general del proyecto, la arquitectura utilizada y los pasos detallados para la instalaci√≥n y ejecuci√≥n del sistema. Es el punto de partida para cualquier usuario o desarrollador. |
| **requirements.txt** | **Dependencias Python** | Contiene la lista de librer√≠as y paquetes de Python necesarios para asegurar un entorno de ejecuci√≥n reproducible. Se utiliza para instalar todas las dependencias del proyecto. |
| **docker-compose.yml** | **Infraestructura** | Archivo clave para la orquestaci√≥n. Define y configura los servicios de la infraestructura como **Kafka**, **Zookeeper**, **PostgreSQL**, la **API**, **dbt** y otros scripts asociados, permitiendo desplegar todo el entorno con un solo comando. |
| **`/ingestas`** | **Ingesta de Datos** | Carpeta que alberga los scripts de Python encargados de la **conexi√≥n y extracci√≥n de datos** desde las APIs oficiales de origen (actualmente Madrid y Valencia). Son los responsables de alimentar el *pipeline* de datos. |
| **`/kafka`** | **Streaming** | Contiene los archivos de configuraci√≥n y *settings* necesarios para el correcto funcionamiento de los brokers de **Kafka** y el servicio de coordinaci√≥n de **Zookeeper**. |
| **`producer.py` / `dashboard_consumer.py`** | **Procesamiento en Tiempo Real** | Scripts esenciales para el sistema de alertas: **`producer.py`** es el encargado de enviar mensajes (datos) a los *topics* de Kafka, y **`dashboard_consumer.py`** los consume para generar y gestionar las alertas en tiempo real. |
| **`/dbt/models`** | **Transformaci√≥n (ELT)** | Aqu√≠ reside la l√≥gica de **Modelado SQL** utilizando la herramienta **dbt (data build tool)**. Los modelos est√°n organizados por etapas: `staging` (limpieza inicial), `intermediate` (l√≥gica de negocio) y `marts` (tablas finales optimizadas para el consumo). |
| **`pull_db_gsheets.py`** | **Reverse ETL** | Script de automatizaci√≥n para la **exportaci√≥n de datos** limpios y transformados (generalmente desde los *marts* de PostgreSQL) hacia **Google Sheets**. Esto facilita el an√°lisis posterior y la visualizaci√≥n en herramientas como Tableau. |

---

## üöÄ Flujo General (Concepto)

El repositorio est√° dise√±ado para un **flujo de datos *end-to-end***:

1.  **Ingesta:** Scripts en `/ingestas` extraen datos de APIs.
2.  **Streaming/Real-Time:** Los datos se publican en Kafka (`producer.py`) y se monitorean (`dashboard_consumer.py`).
3.  **Almacenamiento:** Los datos persisten en **PostgreSQL**.
4.  **Transformaci√≥n:** **dbt** (`/dbt/models`) transforma los datos crudos en modelos listos para el an√°lisis.
5.  **Reverse ETL:** El script `pull_db_gsheets.py` exporta los resultados finales para la visualizaci√≥n de negocio.


## **5. Modelo y Visualizaci√≥n de Datos**

El proyecto se sustenta en una doble capa de visualizaci√≥n para cubrir tanto la monitorizaci√≥n en tiempo real como el an√°lisis hist√≥rico.

#### **5.1. ‚ö° Visualizaci√≥n de Datos a Tiempo Real (Plotly/Dash)**

El dashboard opera a baja latencia, leyendo directamente desde Kafka.

##### Finalidad del Dashboard

* **Alertas inmediatas:** Notificaci√≥n visual con Sem√°foro (Rojo/Verde) al superar los l√≠mites de contaminaci√≥n.
* **An√°lisis R√°pido:** Uso de Gr√°fico Radar para identificar el contaminante responsable de la alerta.

##### L√≥gica Central de Alerta

La clasificaci√≥n se basa en la comparaci√≥n con los l√≠mites de la OMS o normativa local (en $\mu \text{g}/\text{m}^3$):

$$
\text{LIMITES} = \{
    \text{"NO}_2\text{": 40 (Diaria)}, 
    \text{"O}_3\text{": 100 (Horaria)}, 
    \text{"PM}10\text{": 50 (Diaria)}, 
    \text{"PM}2.5\text{": 25 (Diaria)}
\}
$$

| Nivel | Rango (%) Respecto al L√≠mite | Color | Alerta |
| :--- | :--- | :--- | :--- |
| **Bajo** | $< 50\%$ | Verde | ‚úÖ AIRE LIMPIO |
| **Medio** | $50\%$ a $100\%$ | Amarillo | ‚ö†Ô∏è PRECAUCI√ìN |
| **Alto** | $> 100\%$ | Rojo | üö® ALERTA |

##### C√°lculos Clave
* **Normalizaci√≥n (Saturaci√≥n):** $\left( \frac{\text{Valor Actual}}{\text{L√≠mite Legal}} \right) \times 100$.
* **Gr√°fico Radar:** Usa el porcentaje de saturaci√≥n (hasta un m√°ximo de 150%) para dibujar el pol√≠gono. Si cualquier gas supera el $100\%$, el pol√≠gono completo se colorea de rojo.

#### **5.2. üìà Visualizaci√≥n de Datos con Tableau**

**Acceso:** [CalidadAireDP_varias | Tableau Public](https://public.tableau.com/app/profile/pablo.garcia4815/vizes/CalidadAireDP_varias/VisinGlobal-Alertas)

La visualizaci√≥n en Tableau se centra en el an√°lisis de negocio e hist√≥rico a partir de los datos modelados.

##### 1. VISI√ìN GLOBAL - ALERTAS
* **Prop√≥sito:** Mostrar la situaci√≥n actual y las alertas activas en las estaciones.
* **Controles:** Filtro de **Ciudad** y umbrales de alerta ajustables por el usuario.
* **Mapa:** C√≥digo de color (Verde/Rojo) basado en la activaci√≥n de alertas por estaci√≥n.

##### 2. VISI√ìN AL DETALLE - GASES/PART√çCULAS
* **Prop√≥sito:** An√°lisis espec√≠fico de un contaminante seleccionado.
* **Tendencia de 5 horas:** Muestra la evoluci√≥n reciente (series temporales) para identificar subidas o bajadas r√°pidas.
* **Anomal√≠as (Gr√°fico de Barras):** Compara la √∫ltima medici√≥n con el promedio de la √∫ltima hora.
    * **Barra Roja (+):** La contaminaci√≥n est√° subiendo (pico o anomal√≠a).

##### 3. VISTA DE HIST√ìRICOS
* **Prop√≥sito:** Analizar la evoluci√≥n a largo plazo (anual y mensual) de la concentraci√≥n de gases.
* **Filtros:** **Gas**, **Rango de Fechas** y **Estaci√≥n**.
* **Nota:** Los datos hist√≥ricos de Valencia finalizan en 2022 debido a la disponibilidad de la API.

##### 4. ESTACIONES OFFLINE - SIN ENVIAR DATOS
* **Prop√≥sito:** Monitorizar la salud operativa de las estaciones.
* **Funcionalidad:** Muestra una lista de estaciones que no han enviado datos en un per√≠odo definido por el par√°metro "Umbral de horas offline", indicando la **M√°x. Fecha Carga** y las **Horas offline** transcurridas.